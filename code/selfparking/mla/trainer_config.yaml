behaviors:
    Car:
        trainer_type: ppo
        hyperparameters:
            batch_size: 2048
            buffer_size: 20480
            learning_rate: 3.0e-4
            learning_rate_schedule: linear

            # PPO-specific hyperparameters
            beta: 5.0e-3
            epsilon: 0.2
            lambd: 0.95
            num_epoch: 3
        
        network_settings:
            vis_encode_type: simple
            normalize: false
            hidden_units: 256
            num_layers: 2
            memory:
                sequence_length: 64
                memory_size: 128

        # Common trainer config

        max_steps: 5.0e7    
        time_horizon: 128
        summary_freq: 10000
        threaded: true
        
        reward_signals:
            extrinsic:
                strength: 1.0
                gamma: 0.99
